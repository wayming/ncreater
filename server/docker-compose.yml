version: '3.8'

services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.30.0
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - ./weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: ''
      CLUSTER_HOSTNAME: 'node1'
      # gRPC configuration
      GRPC_PORT: "50051"

  proxy:
    build: .
    image: rag_proxy
    ports:
      - "8000:8000"
    environment:
      - WEAVIATE_URL=http://weaviate:8080
      - WEAVIATE_GRPC_PORT=50051
      - OLLAMA_BASE_URL=http://192.168.1.11:11434
    depends_on:
      - weaviate
      - ollama
    networks:
      - rag_network
    restart: unless-stopped
  
  networks:
    rag_network:
      driver: bridge
  # llm:
  #   image: vllm/vllm-openai:latest
  #   ports:
  #     - "5000:5000"
  #   environment:
  #     MODEL: /models/OLMo-12B-Instruct
  #     QUANTIZATION: awq
  #     HOST: 0.0.0.0
  #     DISABLE_API_KEY: "true"
  #   volumes:
  #     - ./models:/models
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #         memory: 24G